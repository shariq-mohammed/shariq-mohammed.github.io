<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>3 | Shariq Mohammed</title>
    <link>/publication_types/3/</link>
      <atom:link href="/publication_types/3/index.xml" rel="self" type="application/rss+xml" />
    <description>3</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 24 Apr 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>3</title>
      <link>/publication_types/3/</link>
    </image>
    
    <item>
      <title>Integrative Bayesian models using Post-selective Inference: a case study in Radiogenomics</title>
      <link>/publication/panigrahi2020integrative/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/publication/panigrahi2020integrative/</guid>
      <description>&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Identifying direct links between gene pathways and clinical endpoints for highly fatal diseases such as cancer is a formidable task. Integrative analyses play a crucial role in modeling these links by relying upon associations between a wealth of intermediary variables and genomic measurements. Motivated to harness phenotypic information about tumors towards a molecular characterization of low-grade gliomas, we develop a data driven Bayesian framework to define sharp models, and calibrate accurately and efficiently uncertainties associated with the promising biological findings.&lt;/p&gt;
&lt;p&gt;The Bayesian methods we propose in the article (i) are amenable to a flexible class of adaptive models, determined via a complex interplay between signals sifted from variable selection algorithms and domain specific knowledge; (ii) have the advantage of computationally efficient high dimensional inference due to a focus on sharp models with fewer parameters, when compared to their non-adaptive counterparts; (iii) exhibit a significantly better reconciliation between model adaptivity and inferential power than state-of-art approaches, when constrained by the curse of dimensionality. Our main workforce involves a carefully constructed conditional likelihood and utilizes a reparameterization map to obtain compact formulae for a selection-corrected posterior. Deploying our methods to investigate radiogenomic characteristics for diffuse low-grade gliomas, we successfully uncover associations between several biologically important gene pathways and patient survival times.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Predictions, role of interventions and effects of a historic national lockdown in India&#39;s response to the COVID-19 pandemic: data science call to arms</title>
      <link>/publication/ray2020predictions/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/publication/ray2020predictions/</guid>
      <description>&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;h2 id=&#34;importance&#34;&gt;Importance&lt;/h2&gt;
&lt;p&gt;India has taken strong and early public health measures for arresting the spread of the COVID-19 epidemic. With only 536 COVID-19 cases and 11 fatalities, India - a democracy of 1.34 billion people - took the historic decision of a 21-day national lockdown on March 25. The lockdown was further extended to May 3, soon after the analysis of this paper was completed.&lt;/p&gt;
&lt;h2 id=&#34;objective&#34;&gt;Objective&lt;/h2&gt;
&lt;p&gt;To study the short- and long-term impact of an initial 21-day lockdown on the total number of COVID-19 cases in India compared to other less severe non-pharmaceutical interventions using epidemiological forecasting models and Bayesian estimation algorithms; to compare effects of hypothetical durations of lockdown from an epidemiological perspective; to study alternative explanations for slower growth rate of the virus outbreak in India, including exploring the association of the number of cases and average monthly temperature; and finally, to outline the pivotal role of reliable and transparent data, reproducible data science methods, tools and products as we reopen the country and prepare for a post lock-down phase of the pandemic.&lt;/p&gt;
&lt;h2 id=&#34;design-setting-and-participants&#34;&gt;Design, Setting, and Participants&lt;/h2&gt;
&lt;p&gt;We use the daily data on the number of COVID-19 cases, of recovered and of deaths from March 1 until April 7, 2020 from the 2019 Novel Coronavirus Visual Dashboard operated by the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). Additionally, we use COVID-19 incidence counts data from Kaggle and the monthly average temperature of major cities across the world from Wikipedia.&lt;/p&gt;
&lt;h2 id=&#34;main-outcome-and-measures&#34;&gt;Main Outcome and Measures&lt;/h2&gt;
&lt;p&gt;The current time-series data on daily proportions of cases and removed (recovered and death combined) from India are analyzed using an extended version of the standard SIR (susceptible, infected, and removed) model. The eSIR model incorporates time-varying transmission rates that help us predict the effect of lockdown compared to other hypothetical interventions on the number of cases at future time points. A Markov Chain Monte Carlo implementation of this model provided predicted proportions of the cases at future time points along with credible intervals (CI).&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;Our predicted cumulative number of COVID-19 cases in India on April 30 assuming a 1-week delay in people&#39;s adherence to a 21-day lockdown (March 25 - April 14) and a gradual, moderate resumption of daily activities after April 14 is 9,181 with upper 95% CI of 72,245. In comparison, the predicted cumulative number of cases under &amp;ldquo;no intervention&amp;rdquo; and &amp;ldquo;social distancing and travel bans without lockdown&amp;rdquo; are 358 thousand and 46 thousand (upper 95% CI of nearly 2.3 million and 0.3 million) respectively. An effective lockdown can prevent roughly 343 thousand (upper 95% CI 1.8 million) and 2.4 million (upper 95% CI 38.4 million) COVID-19 cases nationwide compared to social distancing alone by May 15 and June 15, respectively. When comparing a 21-day lockdown with a hypothetical lockdown of longer duration, we find that 28-, 42-, and 56-day lockdowns can approximately prevent 238 thousand (upper 95% CI 2.3 million), 622 thousand (upper 95% CI 4.3 million), 781 thousand (upper 95% CI 4.6 million) cases by June 15, respectively. We find some suggestive evidence that the COVID-19 incidence rates worldwide are negatively associated with temperature in a crude unadjusted analysis with Pearson correlation estimates [95% confidence interval] between average monthly temperature and total monthly incidence around the world being -0.185 [-0.548, 0.236] for January, -0.110 [-0.362, 0.157] for February, and -0.173 [-0.314, -0.026] for March.&lt;/p&gt;
&lt;h2 id=&#34;conclusions-and-relevance&#34;&gt;Conclusions and Relevance&lt;/h2&gt;
&lt;p&gt;The lockdown, if implemented correctly in the end, has a high chance of reducing the total number of COVID-19 cases in the short term, and buy India invaluable time to prepare its healthcare and disease monitoring system. Our analysis shows we need to have some measures of suppression in place after the lockdown for the best outcome. We cannot heavily rely on the hypothetical prevention governed by meteorological factors such as temperature based on current evidence. From an epidemiological perspective, a longer lockdown between 42-56 days is preferable. However, the lockdown comes at a tremendous price to social and economic health through a contagion process not dissimilar to that of the coronavirus itself. Data can play a defining role as we design post-lockdown testing, reopening and resource allocation strategies.&lt;/p&gt;
&lt;h2 id=&#34;software&#34;&gt;Software&lt;/h2&gt;
&lt;p&gt;Our contribution to data science includes an interactive and dynamic app (covind19.org) with short- and long-term projections updated daily that can help inform policy and practice related to COVID-19 in India. Anyone can visualize the observed data for India and create predictions under hypothetical scenarios with quantification of uncertainties. We make our prediction codes freely available (&lt;a href=&#34;https://github.com/umich-cphds/cov-ind-19&#34;&gt;https://github.com/umich-cphds/cov-ind-19&lt;/a&gt;) for reproducible science and for other COVID-19 affected countries to use them for their prediction and data visualization work.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Spatial risk estimation in Tweedie compound Poisson double generalized linear models</title>
      <link>/publication/halder2019spatial/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/publication/halder2019spatial/</guid>
      <description>&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Tweedie exponential dispersion family constitutes a fairly rich sub-class of the celebrated exponential family. In particular, a member, compound Poisson gamma (CP-g) model has seen extensive use over the past decade for modeling mixed response featuring exact zeros with a continuous response from a gamma distribution. This paper proposes a framework to perform residual analysis on CP-g double generalized linear models for spatial uncertainty quantification. Approximations are introduced to proposed framework making the procedure scalable, without compromise in accuracy of estimation and model complexity; accompanied by sensitivity analysis to model mis-specification. Proposed framework is applied to modeling spatial uncertainty in insurance loss costs arising from automobile collision coverage. Scalability is demonstrated by choosing sizable spatial reference domains comprised of groups of states within the United States of America.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Tweedie exponential dispersion models</title>
      <link>/publication/halder2020spatial/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/publication/halder2020spatial/</guid>
      <description>&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;This paper proposes a general modeling framework that allows for uncertainty quantification at the individual covariate level and spatial referencing, operating withing a double generalized linear model (DGLM). DGLMs provide a general modeling framework allowing dispersion to depend in a link-linear fashion on chosen covariates. We focus on working with Tweedie exponential dispersion models while considering DGLMs, the reason being their recent wide-spread use for modeling mixed response types. Adopting a regularization based approach, we suggest a class of flexible convex penalties derived from an un-directed graph that facilitates estimation of the unobserved spatial effect. Developments are concisely showcased by proposing a co-ordinate descent algorithm that jointly explains variation from covariates in mean and dispersion through estimation of respective model coefficients while estimating the unobserved spatial effect. Simulations performed show that proposed approach is superior to competitors like the ridge and un-penalized versions. Finally, a real data application is considered while modeling insurance losses arising from automobile collisions in the state of Connecticut, USA for the year 2008.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
  </channel>
</rss>
