<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Journal Articles | Shariq Mohammed</title>
    <link>https://shariq-mohammed.github.io/tags/journal-articles/</link>
      <atom:link href="https://shariq-mohammed.github.io/tags/journal-articles/index.xml" rel="self" type="application/rss+xml" />
    <description>Journal Articles</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 01 Feb 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://shariq-mohammed.github.io/img/icon-192.png</url>
      <title>Journal Articles</title>
      <link>https://shariq-mohammed.github.io/tags/journal-articles/</link>
    </image>
    
    <item>
      <title>Network-based Modeling of COVID-19 Dynamics: Early Pandemic Spread in India</title>
      <link>https://shariq-mohammed.github.io/publication/bhattacharyya2021network/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/bhattacharyya2021network/</guid>
      <description>&lt;p&gt;&lt;em&gt;Journal of the Indian Statistical Association &lt;em&gt;(Just Accepted)&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Modeling the dynamics of COVID-19 pandemic spread is a challenging and relevant problem.  Established models for the epidemic spread such as compartmental epidemiological models e.g. Susceptible-Infected-Recovered (SIR) models and its variants, have been discussed extensively in the literature and utilized to forecast the growth of the pandemic across different hot-spots in the world. The standard formulations of SIR models rely upon summary-level data, which may not be  able to fully capture the complete dynamics of the pandemic growth. Since the disease spreads from carriers to susceptible individuals via some form of contact, it inherently relies upon a network of individuals for its growth, with edges established via direct interaction, such as shared physical proximity. Using spatial and individual-level COVID-19 data from the early days (January 30 to April 15, 2020) of the pandemic in India, and under a network-based SIR model framework, we performed state-specific forecasting under multiple scenarios characterized by the basic reproduction number of COVID-19 across 34 Indian states and union territories. We validated our short-term projections using observed case counts and the long-term projections using national sero-survey findings. Based on healthcare availability data, we also performed projections to assess the burdens on the infrastructure along the spectrum of the pandemic growth. We have developed an &lt;a href=&#34;https://bayesrx.shinyapps.io/COV-N/&#34;&gt;interactive dashboard&lt;/a&gt; summarizing our results. Our predictions successfully identified the initial hot-spots of India such as Maharashtra and Delhi, and those that emerged later, such as Madhya Pradesh and Kerala. These models have the potential to inform appropriate policies for isolation and mitigation strategies to contain the pandemic, through a phased approach  by appropriate resource prioritization and allocation.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>GaWRDenMap: A quantitative framework to study the local variation in cell-cell interactions in pancreatic disease subtypes</title>
      <link>https://shariq-mohammed.github.io/publication/krishnan2022gawrdenmap/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/krishnan2022gawrdenmap/</guid>
      <description>&lt;p&gt;&lt;em&gt;Scientific Reports&lt;/em&gt; (2022)&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Spatial pattern modelling concepts are being increasingly used in capturing disease heterogeneity. Quantification of heterogeneity in the tumor microenvironment is extremely important in pancreatic ductal adenocarcinoma (PDAC), which has been shown to co-occur with other pancreatic diseases and neoplasms with certain attributes that make visual discrimination difficult. In this paper, we propose the GaWRDenMap framework, that utilizes the concepts of geographically weighted regression (GWR) and a density function-based classification model, and apply it to a cohort of multiplex immunofluorescence images from patients belonging to six different pancreatic diseases. We used an internal cohort of 228 patients comprised of 34 Chronic Pancreatitis (CP), 71 PDAC, 70 intraductal papillary mucinous neoplasm (IPMN), 16 mucinous cystic neoplasm (MCN), 29 pancreatic intraductal neoplasia (PanIN) and 8  IPMN-associated PDAC patients. We utilize GWR to model the relationship between epithelial cells and immune cells on a spatial grid. The GWR model estimates were used to generate density signatures which were used in subsequent pairwise classification models to distinguish between any two pairs of disease groups. Image-level, as well as subject-level analysis, were performed. When applied to this dataset, our classification model showed significant discrimination ability in multiple pairwise comparisons, in comparison to commonly used abundance-based metrics, like the Morisita-Horn index. The model was able to  best discriminate between CP and PDAC at both the subject- and image-levels. It was also able to reasonably discriminate between PDAC and IPMN. These results point to a potential difference in the spatial arrangement of epithelial and immune cells between CP, PDAC and IPMN, that could be of high  diagnostic significance. Further validation on a more comprehensive dataset would be warranted.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Tweedie exponential dispersion models: An application to insurance rate-making</title>
      <link>https://shariq-mohammed.github.io/publication/halder2020spatial/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/halder2020spatial/</guid>
      <description>&lt;p&gt;&lt;em&gt;Scandinavian Actuarial Journal&lt;/em&gt; (2021).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;In this paper we propose a statistical modeling framework that contributes to advancing methods for modeling insurance policy premium in the actuarial literature. Specification of separate frequency and severity models, accounting for territorial risk and performing accurate inference are some of the challenges actuaries face while modeling policy premium. We focus on building a methodology that builds parsimonious and interpretable models for modeling policy premium. Policy premiums are characterized to follow a semi-continuous probability distribution, featuring a non-zero probability mass at zero along with a positive continuous support. Interpretability is a concern when quantifying risks that policy premium face from spatial variation. Risk conferred from spatial sources is often treated as an unobserved. Commonly used strategies in the literature are known to successfully quantify the variation, but do not necessarily produce interpretable estimates. Furthermore, resorting to two-part frequency-severity models leaves the actuary indecisive about the specification of covariates and spatial effects. The proposed methods in the paper considers a more parsimonious approach by resorting to zero-adjusted models for policy premium, that models both the mean policy-premium and the associated dispersion around the mean. Quantification of variation from spatial sources is proposed for the mean model. Allowing for a non-constant dispersion across observations results in a better estimate of the underlying variability, producing superior estimates for coefficients. The novelty of the proposed approach lies in the framework developed, that allows for joint estimation of effect of policy or individual characteristics on both the mean policy premium and dispersion, while quantifying spatial variability in the mean model. The developed methods are applied to a database featuring policy premiums arising from the collision coverage in insurance policies for motor vehicles within the state of Connecticut, USA for the year 2008.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Scalable spatio-temporal Bayesian analysis of high-dimensional electroencephalography data</title>
      <link>https://shariq-mohammed.github.io/publication/mohammed2021scalable/</link>
      <pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/mohammed2021scalable/</guid>
      <description>&lt;p&gt;&lt;em&gt;Canadian Journal of Statistics&lt;/em&gt; (2021).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;We present a scalable Bayesian modeling approach for identifying brain regions that respond to a certain stimulus and use them to classify subjects. We specifically deal with multi-subject electroencephalography (EEG) data with a binary response distinguishing between alcoholic and control groups. The covariates are matrix-variate with measurements taken for each subject at different locations across multiple time points. EEG data has a complex structure with both spatial and temporal attributes to it. We use a divide-and-conquer strategy to build multiple local models, that is, one model at each time point separately. We employ Bayesian variable selection approaches using a structured continuous spike-and-slab prior to identify the locations which respond to a certain stimulus. We incorporate the spatio-temporal structure through a Kronecker product of the spatial and temporal correlation matrices. We develop a highly scalable estimation algorithm using likelihood approximation to deal with large number of parameters in the model. Variable selection is done via clustering of the locations based on their duration of activation. We use scoring rules to evaluate the prediction performance. We perform simulation studies to demonstrate the efficiency of our scalable algorithm in terms of estimation and fast computation. We present results using our scalable approach for a case study on multi-subject EEG data.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Discriminating pseudoprogression and true progression in diffuse infiltrating glioma using multi-parametric MRI data through deep learning</title>
      <link>https://shariq-mohammed.github.io/publication/lee2020discriminating/</link>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/lee2020discriminating/</guid>
      <description>&lt;p&gt;&lt;em&gt;Scientific Reports&lt;/em&gt; (2020).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Differentiating pseudoprogression from true tumor progression has become a significant challenge in follow-up of diffuse infiltrating gliomas, particularly high grade, which leads to a potential treatment delay for patients with early glioma recurrence. In this study, we proposed to use a multiparametric MRI data as a sequence input for the convolutional neural network with the recurrent neural network based deep learning structure to discriminate between pseudoprogression and true tumor progression. In this study, 43 biopsy-proven patient data identified as diffuse infiltrating glioma patients whose disease progressed/recurred were used. The dataset consists of five original MRI sequences; pre-contrast T1-weighted, post-contrast T1-weighted, T2-weighted, FLAIR, and ADC images as well as two engineered sequences; T1post – T1pre and T2 – FLAIR. Next, we used three CNN-LSTM models with a different set of sequences as input sequences to pass through CNN-LSTM layers. We performed 3-fold cross-validation in the training dataset and generated the boxplot, accuracy, and ROC curve, AUC from each trained model with the test dataset to evaluate models. The mean accuracy for VGG16 models ranged from 0.44 to 0.60 and the mean AUC ranged from 0.47 to 0.59. For CNN-LSTM model, the mean accuracy ranged from 0.62 to 0.75 and the mean AUC ranged from 0.64 to 0.81. The performance of the proposed CNN-LSTM with multiparametric sequence data was found to outperform the popular convolutional CNN with a single MRI sequence. In conclusion, incorporating all available MRI sequences into a sequence input for a CNN-LSTM model improved diagnostic performance for discriminating between pseudoprogression and true tumor progression.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>A Bayesian 2D functional linear model for gray-level co-occurrence matrices in texture analysis of lower grade gliomas</title>
      <link>https://shariq-mohammed.github.io/publication/chekouo2020bayesian/</link>
      <pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/chekouo2020bayesian/</guid>
      <description>&lt;p&gt;&lt;em&gt;NeuroImage: Clinical&lt;/em&gt; (2020).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;In cancer radiomics, textural features evaluated from image intensity-derived gray-level co-occurrence matrices (GLCMs) have been studied to evaluate gray-level spatial dependence within the regions of interest in the brain. Most of these analysis work with summary statistics (or texture-based features) constructed using the GLCM entries, and potentially overlook other structural properties in the GLCM.  In our proposed Bayesian framework, we treat each GLCM  as a realization of a two-dimensional stochastic functional process observed with error at discrete time points. The latent process is then combined with the outcome model to evaluate the prediction performance. We use simulation studies to assess the performance of our method and apply it to data collected from individuals with lower grade gliomas. We found our approach to outperform competing methods that use only summary statistics to predict isocitrate dehydrogenase (IDH) mutation status.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Density-based classification in diabetic retinopathy through thickness of retinal layers from optical coherence tomography</title>
      <link>https://shariq-mohammed.github.io/publication/mohammed2020density/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/mohammed2020density/</guid>
      <description>&lt;p&gt;&lt;em&gt;Scientific Reports&lt;/em&gt; (2020).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Diabetic retinopathy (DR) is a severe retinal disorder that can lead to vision loss, however, its underlying mechanism has not been fully understood. Previous studies have taken advantage of Optical Coherence Tomography (OCT) and shown that the thickness of individual retinal layers are affected in patients with DR. However, most studies analyzed the thickness by calculating summary statistics from retinal thickness maps of the macula region. This study aims to apply a density function-based statistical framework to the thickness data obtained through OCT, and to compare the predictive power of various retinal layers to assess the severity of DR. We used a prototype data set of 107 subjects which are comprised of 38 non-proliferative DR (NPDR), 28 without DR (NoDR), and 41 controls. Based on the thickness profiles, we constructed novel features which capture the variation in the distribution of the pixel-wise retinal layer thicknesses from OCT. We quantified the predictive power of each of the retinal layers to distinguish between all three pairwise comparisons of the severity in DR (NoDR vs NPDR, controls vs NPDR and controls vs NoDR). When applied to this preliminary DR data set, our density-based method demonstrated better predictive results compared with simple summary statistics. Furthermore, our results indicate considerable differences in retinal layer structuring based on the severity of DR. We found that: (a) the outer plexiform layer is the most discriminative layer for classifying NoDR vs NPDR; (b) the outer plexiform, inner nuclear and ganglion cell layers are the strongest biomarkers for discriminating controls from NPDR; and (c) the inner nuclear layer distinguishes best between controls and NoDR.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Classification of high-dimensional electroencephalography data with location selection using structured spike-and-slab prior</title>
      <link>https://shariq-mohammed.github.io/publication/mohammed2020classification/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/mohammed2020classification/</guid>
      <description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;Invited for Statistical Analysis and Data Mining Best Paper Session at Joint Statistical Meetings 2022.&lt;/strong&gt;&lt;/em&gt; &lt;a href=&#34;https://ww2.amstat.org/meetings/jsm/2022/onlineprogram/ActivityDetails.cfm?SessionID=221965&#34;&gt;JSM 2022 Program&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Statistical Analysis and Data Mining: The ASA Data Science Journal&lt;/em&gt; (2020).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;With the advent of modern technologies, it is increasingly common to deal with data of large dimensions in various scientific fields of study. In this paper, we develop a Bayesian approach for the classification of multi-subject high-dimensional electroencephalography (EEG) data. In this EEG data, we have a matrix of covariates corresponding to each subject from either the alcoholic or control group. The matrix covariates have a natural spatial correlation based on the locations of the brain, and temporal correlation as the measurements are taken over time. We employ a divide and conquer strategy by building multiple local Bayesian models at each time point separately. We incorporate the spatial structure through the structured spike-and-slab prior, which has inherent variable selection properties. The temporal structure is incorporated within the prior by learning from the local model from the previ- ous time point. We pool the information from the local models and use a weighted average to design a prediction method. We perform simulation studies to show the efficiency of our approach and demonstrate the local Bayesian modeling with a case study on EEG data.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Predictions, role of interventions and effects of a historic national lockdown in India’s response to the COVID-19 pandemic: data science call to arms</title>
      <link>https://shariq-mohammed.github.io/publication/ray2020predictions/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/ray2020predictions/</guid>
      <description>&lt;p&gt;&lt;em&gt;Harvard Data Science Review&lt;/em&gt; (2020).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;With only 536 cases and 11 fatalities, India took the historic decision of a 21-day national lockdown on March 25. The lockdown was first extended to May 3 soon after the analysis of this paper was completed, and then to May 18 while this paper was being revised. In this paper, we use a Bayesian extension of the Susceptible-Infected-Removed (eSIR) model designed for intervention forecasting to study the short- and long-term impact of an initial 21-day lockdown on the total number of COVID-19 infections in India compared to other less severe non-pharmaceutical interventions. We compare effects of hypothetical durations of lockdown on reducing the number of active and new infections. We find that the lockdown, if implemented correctly, can reduce the total number of cases in the short term, and buy India invaluable time to prepare its healthcare and disease-monitoring system. Our analysis shows we need to have some measures of suppression in place after the lockdown for increased benefit (as measured by reduction in the number of cases). A longer lockdown between 42-56 days is preferable to substantially “flatten the curve” when compared to 21-28 days of lockdown. Our models focus solely on projecting the number of COVID-19 infections and thus, inform policymakers about one aspect of this multi-faceted decision-making problem. We conclude with a discussion on the pivotal role of increased testing, reliable and transparent data, proper uncertainty quantification, accurate interpretation of forecasting models, reproducible data science methods and tools that can enable data-driven policymaking during a pandemic. Our software products are available at &lt;a href=&#34;covind19.org&#34;&gt;covind19.org&lt;/a&gt;.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian variable selection using spike-and-slab priors with application to high dimensional electroencephalography data by local modelling</title>
      <link>https://shariq-mohammed.github.io/publication/mohammed2019bayesian/</link>
      <pubDate>Fri, 26 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/mohammed2019bayesian/</guid>
      <description>&lt;p&gt;&lt;em&gt;Journal of the Royal Statistical Society: Series C (Applied Statistics)&lt;/em&gt; (2019).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Because of the immense technological advances, very often we encounter data in high dimensions. Any set of measurements taken at multiple time points for multiple subjects leads to data of more than two dimensions (a matrix of covariates for each subject). We present a Bayesian variable‐selection method to identify the active regions in the brain as a response to a certain stimulus. We build binary classification models of subject level responses by using binary regression with Gaussian models on the latent variables. We also study the scaled normal priors on the latent variables, as they cover a large family of distributions. We use continuous spike‐and‐slab priors to incorporate variable selection within the modelling. Because of the computational complexity, we build many local (at different time points) models and make predictions by utilizing the temporal structure between the local models. We perform two‐stage variable selection for each of these local models. We demonstrate the effectiveness of such modelling through the results of a simulation study. We then present the performance of these models on multisubject neuroimaging (electroencephalography) data to study the effects on the functional states of the frontal cortex and parietal lobe for chronic exposure of alcohol.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Assessing malaria using neutral zone classifiers with mixture discriminant analysis on 2D images of red blood cells</title>
      <link>https://shariq-mohammed.github.io/publication/mohammed2019assessing/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://shariq-mohammed.github.io/publication/mohammed2019assessing/</guid>
      <description>&lt;p&gt;&lt;em&gt;Journal of Biostatistics and Epidemiology&lt;/em&gt; (2019).&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract:&lt;/h1&gt;
&lt;p&gt;Background and Aim: We aim to build a classifier to distinguish between malaria-infected red blood cells (RBCs) and healthy cells using the two-dimensional (2D) microscopic images of RBCs. We demonstrate the process of cell segmentation and feature extraction from the 2D images.&lt;/p&gt;
&lt;p&gt;Methods and Materials: We describe an approach to address the problem using mixture discriminant analysis (MDA) on the 2D image profiles of the RBCs. The extracted features are used with Gaussian MDA to distinguish between healthy and malaria infected cells. We also use the neutral zone classifiers where ambiguous cases are identified separately by the classifier.&lt;/p&gt;
&lt;p&gt;Results: We compare the classification results from the regular classifiers such as linear discriminant analysis (LDA) or MDA and the methods where neutral zone classifiers are used. We see that including the neutral zone improves the classification results by controlling the false positive and false negatives. The number of misclassifications are seen to be lower than the case without neutral zone classifiers.&lt;/p&gt;
&lt;p&gt;Conclusion: This paper presents an alternative approach for classification by incorporating neutral zone classifier approach, where a prediction is not made for the ambiguous cases. From the data analysis we see that this approach based on neutral zone classifiers presents a useful alternative in classification problems for various applications.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
  </channel>
</rss>
